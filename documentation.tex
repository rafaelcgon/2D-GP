\documentclass[12pt,a4paper]{article}%[a4paper,portuguese,12pt,pdftex]{article} %article
\usepackage{ucs}
\usepackage{amsfonts}		 		% usar fontes p/ REAL,IMAGINARIO,etc
\usepackage{indentfirst}			% espacamento no 1o. paragrafo
\usepackage[utf8x]{inputenc} 
\usepackage{amssymb,amsmath}			% pacote simbolos e matematico AMS
\usepackage{textcomp}
\usepackage{natbib}				% estilo de citacao no texto
\usepackage{wasysym}
\usepackage{fancyhdr}
\renewcommand{\baselinestretch}{1.5}		% espaco entre linhas
\topmargin -1cm					% margem superior
\oddsidemargin 0.5cm				% margem esquerda
\textwidth 15cm					% largura da pagina
\textheight 23.7cm				% altura da pagina
\usepackage{color}
\usepackage{lscape}
\usepackage{graphicx}
\usepackage{epsfig}

\title{Learning velocity fields from sparse data using Gaussian process regression}
\author{Rafael Gon\c{c}alves}

\begin{document}

\section{Interpolation of drifters tracks and Lagrangian velocity estimates}

The drifters from the LASER experiment provided positions at intervals of approximately 5 minutes. 
These intervals may vary considerably due to the state of the GPS sensors (e.g. low battery) or due to 
the sea state, as waves might flip the undrogued drifters, interrupting the GPS transmission.
The interpolation of the positions of the drifters is carried out in order to have all drifters' tracks in 
the same regular time frame. Here, two different approaches were considered for the interpolation: the 
B-spline function and Gaussian Process regression. In both cases, the time series of Longitude and Latitude 
recorded by each drifter are interpolated in a time frame with 10 minutes resolution.

For the B-splines interpolation, we used an algorithm that follows the formalism described in 
\cite{Dierckx1975,Dierckx1981,Dierckx1982,Dierckx1993}. The algorithm uses a 
smoothing condition $S$, for which the interpolated curve must satisfy:

\begin{equation}
 \sum_{i=0}^N(y_i - f_i)^2 \le S
\end{equation}

where $f$ is the smoothed interpolation of $y$, and $N$ is the number of data points used. 
The amount of smoothing alowed by $S$ should be enough to smooth out spikes that might occur 
due to the GPS positioning uncertainty \citep{Haza20?}, and also to avoid overfitting and ill-posed 
problems \citep{Dierckx1981}. Here, the time series of Latitude and Longitude were 
interpolated with $S=0.001$. One example of an interpolated drifter track is shown on Figure \ref{fig-track}.
The B-spline algorithm enables the computation of its derivatives (see \cite{Dierckx1975}). 
The first derivative of the Longitude and Latitude B-splines were used to compute the zonal and meridional 
components of the Lagrangian velocities.

In the Gaussian process regression approach, the quantity of interest is thought as a stochastic process in which 
any finite number of samples have a joint Gaussian distribution \citep{Rasmussen2006}. The Gaussian process is completely 
defined by a mean function and a covariance function. Considering a set of observations $O=(\bf{T},\bf{Y})$, where 
$\bf{Y}$ is a vector with Latitudes or Longitudes recorded by a drifter at times $\bf{T}$, the mean function of 
the Gaussian process is given by:

\begin{equation}
 f(\bf{T_*}) = K(\bf{T_*},\bf{T})(K(\bf{T},\bf{T}) + \sigma_N^2I)^{-1}Y 
\end{equation}
Where $f$ is the estimate of Latitude or Longitude at times $\bf{T_*}$, $K$ is the covariance matrix, 
$\sigma_N$ is a noise amplitude considered for the observations, and $I$ is the identity matrix. 
The entries of $K$ are given by the covariance function $k$, which here is the squared exponential:
\begin{equation}
 k(t_i,t_j) = \sigma^2 exp(-\frac{(t_i-t_j)^2}{2\tau^2}) 
\end{equation}

where t is time, $\sigma$ is the variance and $\tau$ is a decorrelation time scale. 

The time series of Longitude and Latitude of each drifter are 
treated as separate Gaussian processes, so that the hyperparameters ($\sigma_N$, $\sigma$ and $\tau$) of 
their respective covariance functions can be set with different values. 
The first guess of the hyperparameters is arbitrary, then they are optimized by minimizing the log marginal 
likelihood $log p(\bf{Y}|\bf{T},\sigma_N,\sigma,\tau)$ \citep{Rasmussen2006}. Histograms with the posterior 
values of the hyperparameters of each drifter are presented on Figure \reg{fig-hyperparam}.

In order to compare both methods, a root-mean-squared difference was computed for each time $t$.
\begin{equation}
 r(t) = \sqrt{\frac{1}{N}\sum_{i=1}^N(g_i(t) - f_i(t))^2}
\end{equation}

Where $g_i$ is the B-spline estimate of the Latitude or Longitude of the i-th drifter, $f_i$ is the 
respective Gaussian process estimate, and N is the total number of drifters used. Figure \ref{fig-rms1} 
presents the time series of $r$ considering all 330 drifters available (drogued and undrogued). 



\begin{figure}
\noindent\includegraphics[width=36pc]{drifter_tracks.png}
\caption{The positions recorded by one drifter over 2 days (black dots) and interpolated 
positions using the cubic B-spline (blue dots) and Gaussian Process (red dots).}
\label{fig-track}
\end{figure}

\begin{figure}
\noindent\includegraphics[width=36pc]{velocity_components.png}
\caption{Lagrangian velocity components estimated from the cubic B-spline interpolation (blue) 
and from the Gaussian Process (red).}
\label{fig-track}
\end{figure}

\begin{figure}
\noindent\includegraphics[width=36pc]{hyp_histograms.png}
\caption{Histograms with values of hyperparameters for each drifter.  }
\label{fig-hyperparam}
\end{figure}

\end{document}


%1] P. Dierckx, "An algorithm for smoothing, differentiation and
%   integration of experimental data using spline functions",
%   J.Comp.Appl.Maths 1 (1975) 165-184.
%.. [2] P. Dierckx, "A fast algorithm for smoothing data on a rectangular
%   grid while using spline functions", SIAM J.Numer.Anal. 19 (1982)
%   1286-1304.
%.. [3] P. Dierckx, "An improved algorithm for curve fitting with spline
%   functions", report tw54, Dept. Computer Science,K.U. Leuven, 1981.
%.. [4] P. Dierckx, "Curve and surface fitting with splines", Monographs on
%   Numerical Analysis, Oxford University Press, 1993.
